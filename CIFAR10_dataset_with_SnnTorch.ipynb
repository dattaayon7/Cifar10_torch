{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOymnaAE/IEDyQSP4eO0YGP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dattaayon7/Cifar10_torch/blob/main/CIFAR10_dataset_with_SnnTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiivDr0OHvaE",
        "outputId": "d35789c4-4ee6-42ca-f936-be9fd57a7d3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: snntorch in /usr/local/lib/python3.7/dist-packages (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.3.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from snntorch) (3.2.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from snntorch) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1.0->snntorch) (4.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->snntorch) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->snntorch) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->snntorch) (2022.2.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install snntorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import snntorch as snn\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch import spikegen\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools"
      ],
      "metadata": {
        "id": "--Y5Gm0yH5hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leaky neuron model, overriding the backward pass with a custom function\n",
        "class LeakySurrogate(nn.Module):\n",
        "  def __init__(self, beta, threshold=1.0):\n",
        "      super(LeakySurrogate, self).__init__()\n",
        "\n",
        "      # initialize decay rate beta and threshold\n",
        "      self.beta = beta\n",
        "      self.threshold = threshold\n",
        "      self.spike_op = self.SpikeOperator.apply\n",
        "\n",
        "  # the forward function is called each time we call Leaky\n",
        "  def forward(self, input_, mem):\n",
        "    spk = self.spike_op((mem-self.threshold))  # call the Heaviside function\n",
        "    reset = (spk * self.threshold).detach()  # removes spike_op gradient from reset\n",
        "    mem = self.beta * mem + input_ - reset  # Eq (1)\n",
        "    return spk, mem\n",
        "\n",
        "  # Forward pass: Heaviside function\n",
        "  # Backward pass: Override Dirac Delta with the Spike itself\n",
        "  @staticmethod\n",
        "  class SpikeOperator(torch.autograd.Function):\n",
        "      @staticmethod\n",
        "      def forward(ctx, mem):\n",
        "          spk = (mem > 0).float() # Heaviside on the forward pass: Eq(2)\n",
        "          ctx.save_for_backward(spk)  # store the spike for use in the backward pass\n",
        "          return spk\n",
        "\n",
        "      @staticmethod\n",
        "      def backward(ctx, grad_output):\n",
        "          (spk,) = ctx.saved_tensors  # retrieve the spike\n",
        "          grad = grad_output * spk # scale the gradient by the spike: 1/0\n",
        "          return grad"
      ],
      "metadata": {
        "id": "czjFGgqZIBuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lif1 = LeakySurrogate(beta=0.9)"
      ],
      "metadata": {
        "id": "BbJCflpoIQDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lif1 = snn.Leaky(beta=0.9)"
      ],
      "metadata": {
        "id": "DXt5oWtlIYAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader arguments\n",
        "batch_size = 128\n",
        "data_path='/data/CIFAR10'\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "58nfiSqZIarz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,), (0.5))])\n",
        "\n",
        "CIFAR10_train = datasets.CIFAR10(data_path, train=True, download=True, transform=transform)\n",
        "CIFAR10_test = datasets.CIFAR10(data_path, train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eInH_xgIiSx",
        "outputId": "71bcc263-fbbc-471b-eaab-2a829b4bca05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(CIFAR10_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(CIFAR10_test, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ioiCio6PI2vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#   Convert from tensor image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5                      #unnormalizing\n",
        "    plt.imshow(np.transpose(img, (1,2,0)))"
      ],
      "metadata": {
        "id": "ixmsiOFop1tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to Grayscale\n",
        "\n",
        "import torchvision as tv\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "dataDir         = '/data/CIFAR10'\n",
        "trainTransform  = tv.transforms.Compose([tv.transforms.Grayscale(num_output_channels=3),\n",
        "                                    tv.transforms.ToTensor(),\n",
        "                                    tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainSet        = tv.datasets.CIFAR10(dataDir, train=True, download=True, transform=trainTransform)\n",
        "dataloader      = data.DataLoader(trainSet, batch_size=1, shuffle=True, num_workers=0)\n",
        "\n",
        "images,labels  = iter(dataloader).next()\n",
        "\n",
        "print (images.size())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_19j0OpTDxLm",
        "outputId": "965e6592-2808-4379-df01-19bfc6943fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "torch.Size([1, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Network Architecture\n",
        "num_inputs = 28*28\n",
        "num_hidden = 1000\n",
        "num_outputs = 10\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 25\n",
        "beta = 0.95"
      ],
      "metadata": {
        "id": "wODpzakhJJJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Initialize hidden states at t=0\n",
        "        mem1 = self.lif1.init_leaky()\n",
        "        mem2 = self.lif2.init_leaky()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            cur1 = self.fc1(x)\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "\n",
        "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "9l6KfTJiJR05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass data into the network, sum the spikes over time\n",
        "# and compare the neuron with the highest number of spikes\n",
        "# with the target\n",
        "\n",
        "def print_batch_accuracy(data, targets, train=False):\n",
        "    output, _ = net(data.view(batch_size, -1))\n",
        "    _, idx = output.sum(dim=0).max(1)\n",
        "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
        "\n",
        "    if train:\n",
        "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
        "    else:\n",
        "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
        "\n",
        "def train_printer():\n",
        "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
        "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
        "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
        "    print_batch_accuracy(data, targets, train=True)\n",
        "    print_batch_accuracy(test_data, test_targets, train=False)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "OvNtzviHJb6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "XFuvZRbYJqXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "EgwTU3-EJuLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, targets = next(iter(train_loader))\n",
        "data = data.to(device)\n",
        "targets = targets.to(device)"
      ],
      "metadata": {
        "id": "0VEaD30qJxAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spk_rec, mem_rec = net(data.view(batch_size, -1))\n"
      ],
      "metadata": {
        "id": "lQAsNxRlJ1nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mem_rec.size())\n",
        "torch.Size([25, 128, 10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UTfB09kJ9Qx",
        "outputId": "9d1f18d7-e862-4264-ebcf-f03f8117cd91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25, 128, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([25, 128, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the total loss value\n",
        "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "# sum loss at every step\n",
        "for step in range(num_steps):\n",
        "  loss_val += loss(mem_rec[step], targets)"
      ],
      "metadata": {
        "id": "SE2hI3G1KCE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training loss: {loss_val.item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52kKM929KHFw",
        "outputId": "8358ed58-c827-417c-fe90-20238fb038a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 61.524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_batch_accuracy(data, targets, train=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsdQtvxGKKoi",
        "outputId": "8ab2875d-12d3-4a76-f928-ad86b59d5a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set accuracy for a single minibatch: 7.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear previously stored gradients\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# calculate the gradients\n",
        "loss_val.backward()\n",
        "\n",
        "# weight update\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "Yzxtn-suKOAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate new network outputs using the same data\n",
        "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
        "\n",
        "# initialize the total loss value\n",
        "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "# sum loss at every step\n",
        "for step in range(num_steps):\n",
        "  loss_val += loss(mem_rec[step], targets)"
      ],
      "metadata": {
        "id": "5e49hMunKTlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training loss: {loss_val.item():.3f}\")\n",
        "print_batch_accuracy(data, targets, train=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxVLGH1-KYqj",
        "outputId": "f050034a-a6f2-4ffe-9f70-e264724165c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 48.400\n",
            "Train set accuracy for a single minibatch: 41.41%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0\n",
        "\n",
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "    iter_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data, targets in train_batch:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        net.train()\n",
        "        spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
        "\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "        for step in range(num_steps):\n",
        "            loss_val += loss(mem_rec[step], targets)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        with torch.no_grad():\n",
        "            net.eval()\n",
        "            test_data, test_targets = next(iter(test_loader))\n",
        "            test_data = test_data.to(device)\n",
        "            test_targets = test_targets.to(device)\n",
        "\n",
        "            # Test set forward pass\n",
        "            test_spk, test_mem = net(test_data.view(batch_size, -1))\n",
        "\n",
        "            # Test set loss\n",
        "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
        "            for step in range(num_steps):\n",
        "                test_loss += loss(test_mem[step], test_targets)\n",
        "            test_loss_hist.append(test_loss.item())\n",
        "\n",
        "            # Print train/test loss/accuracy\n",
        "            if counter % 30 == 0:\n",
        "                train_printer()\n",
        "            counter += 1\n",
        "            iter_counter +=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JHhW6B-KcRf",
        "outputId": "90c07118-b85d-4b01-f7f5-ee58649f478e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Iteration 0\n",
            "Train Set Loss: 55.12\n",
            "Test Set Loss: 56.81\n",
            "Train set accuracy for a single minibatch: 35.16%\n",
            "Test set accuracy for a single minibatch: 27.34%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 30\n",
            "Train Set Loss: 43.74\n",
            "Test Set Loss: 61.92\n",
            "Train set accuracy for a single minibatch: 42.97%\n",
            "Test set accuracy for a single minibatch: 29.69%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 60\n",
            "Train Set Loss: 53.97\n",
            "Test Set Loss: 56.81\n",
            "Train set accuracy for a single minibatch: 32.03%\n",
            "Test set accuracy for a single minibatch: 29.69%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 90\n",
            "Train Set Loss: 56.18\n",
            "Test Set Loss: 53.47\n",
            "Train set accuracy for a single minibatch: 43.75%\n",
            "Test set accuracy for a single minibatch: 31.25%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 120\n",
            "Train Set Loss: 49.41\n",
            "Test Set Loss: 53.46\n",
            "Train set accuracy for a single minibatch: 41.41%\n",
            "Test set accuracy for a single minibatch: 35.16%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 150\n",
            "Train Set Loss: 47.89\n",
            "Test Set Loss: 49.67\n",
            "Train set accuracy for a single minibatch: 39.84%\n",
            "Test set accuracy for a single minibatch: 33.59%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 180\n",
            "Train Set Loss: 53.04\n",
            "Test Set Loss: 46.78\n",
            "Train set accuracy for a single minibatch: 37.50%\n",
            "Test set accuracy for a single minibatch: 42.19%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 210\n",
            "Train Set Loss: 56.35\n",
            "Test Set Loss: 55.55\n",
            "Train set accuracy for a single minibatch: 31.25%\n",
            "Test set accuracy for a single minibatch: 23.44%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 240\n",
            "Train Set Loss: 51.46\n",
            "Test Set Loss: 51.66\n",
            "Train set accuracy for a single minibatch: 32.81%\n",
            "Test set accuracy for a single minibatch: 39.06%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 270\n",
            "Train Set Loss: 57.74\n",
            "Test Set Loss: 51.98\n",
            "Train set accuracy for a single minibatch: 28.91%\n",
            "Test set accuracy for a single minibatch: 34.38%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 300\n",
            "Train Set Loss: 51.63\n",
            "Test Set Loss: 57.32\n",
            "Train set accuracy for a single minibatch: 39.06%\n",
            "Test set accuracy for a single minibatch: 35.94%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 330\n",
            "Train Set Loss: 50.03\n",
            "Test Set Loss: 57.46\n",
            "Train set accuracy for a single minibatch: 36.72%\n",
            "Test set accuracy for a single minibatch: 36.72%\n",
            "\n",
            "\n",
            "Epoch 0, Iteration 360\n",
            "Train Set Loss: 54.30\n",
            "Test Set Loss: 58.70\n",
            "Train set accuracy for a single minibatch: 32.03%\n",
            "Test set accuracy for a single minibatch: 30.47%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 0\n",
            "Train Set Loss: 60.07\n",
            "Test Set Loss: 56.00\n",
            "Train set accuracy for a single minibatch: 35.94%\n",
            "Test set accuracy for a single minibatch: 28.12%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 30\n",
            "Train Set Loss: 52.78\n",
            "Test Set Loss: 47.96\n",
            "Train set accuracy for a single minibatch: 39.06%\n",
            "Test set accuracy for a single minibatch: 39.06%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 60\n",
            "Train Set Loss: 50.30\n",
            "Test Set Loss: 51.56\n",
            "Train set accuracy for a single minibatch: 44.53%\n",
            "Test set accuracy for a single minibatch: 32.81%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 90\n",
            "Train Set Loss: 56.40\n",
            "Test Set Loss: 54.69\n",
            "Train set accuracy for a single minibatch: 29.69%\n",
            "Test set accuracy for a single minibatch: 39.84%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 120\n",
            "Train Set Loss: 55.02\n",
            "Test Set Loss: 62.43\n",
            "Train set accuracy for a single minibatch: 33.59%\n",
            "Test set accuracy for a single minibatch: 32.03%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 150\n",
            "Train Set Loss: 51.89\n",
            "Test Set Loss: 50.02\n",
            "Train set accuracy for a single minibatch: 42.19%\n",
            "Test set accuracy for a single minibatch: 35.16%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 180\n",
            "Train Set Loss: 46.27\n",
            "Test Set Loss: 54.21\n",
            "Train set accuracy for a single minibatch: 43.75%\n",
            "Test set accuracy for a single minibatch: 36.72%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 210\n",
            "Train Set Loss: 51.62\n",
            "Test Set Loss: 56.40\n",
            "Train set accuracy for a single minibatch: 42.19%\n",
            "Test set accuracy for a single minibatch: 35.16%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 240\n",
            "Train Set Loss: 50.44\n",
            "Test Set Loss: 48.26\n",
            "Train set accuracy for a single minibatch: 38.28%\n",
            "Test set accuracy for a single minibatch: 36.72%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 270\n",
            "Train Set Loss: 47.44\n",
            "Test Set Loss: 56.42\n",
            "Train set accuracy for a single minibatch: 42.97%\n",
            "Test set accuracy for a single minibatch: 28.91%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 300\n",
            "Train Set Loss: 52.88\n",
            "Test Set Loss: 49.65\n",
            "Train set accuracy for a single minibatch: 33.59%\n",
            "Test set accuracy for a single minibatch: 32.81%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 330\n",
            "Train Set Loss: 52.11\n",
            "Test Set Loss: 53.90\n",
            "Train set accuracy for a single minibatch: 35.16%\n",
            "Test set accuracy for a single minibatch: 36.72%\n",
            "\n",
            "\n",
            "Epoch 1, Iteration 360\n",
            "Train Set Loss: 58.32\n",
            "Test Set Loss: 52.60\n",
            "Train set accuracy for a single minibatch: 35.16%\n",
            "Test set accuracy for a single minibatch: 36.72%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 0\n",
            "Train Set Loss: 51.67\n",
            "Test Set Loss: 55.57\n",
            "Train set accuracy for a single minibatch: 35.94%\n",
            "Test set accuracy for a single minibatch: 28.91%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 30\n",
            "Train Set Loss: 51.33\n",
            "Test Set Loss: 57.76\n",
            "Train set accuracy for a single minibatch: 35.16%\n",
            "Test set accuracy for a single minibatch: 42.97%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 60\n",
            "Train Set Loss: 49.22\n",
            "Test Set Loss: 57.28\n",
            "Train set accuracy for a single minibatch: 39.84%\n",
            "Test set accuracy for a single minibatch: 33.59%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 90\n",
            "Train Set Loss: 60.07\n",
            "Test Set Loss: 51.40\n",
            "Train set accuracy for a single minibatch: 28.91%\n",
            "Test set accuracy for a single minibatch: 37.50%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 120\n",
            "Train Set Loss: 50.98\n",
            "Test Set Loss: 50.76\n",
            "Train set accuracy for a single minibatch: 40.62%\n",
            "Test set accuracy for a single minibatch: 33.59%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 150\n",
            "Train Set Loss: 47.82\n",
            "Test Set Loss: 58.63\n",
            "Train set accuracy for a single minibatch: 38.28%\n",
            "Test set accuracy for a single minibatch: 30.47%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 180\n",
            "Train Set Loss: 46.66\n",
            "Test Set Loss: 48.81\n",
            "Train set accuracy for a single minibatch: 38.28%\n",
            "Test set accuracy for a single minibatch: 33.59%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 210\n",
            "Train Set Loss: 51.29\n",
            "Test Set Loss: 54.62\n",
            "Train set accuracy for a single minibatch: 38.28%\n",
            "Test set accuracy for a single minibatch: 26.56%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 240\n",
            "Train Set Loss: 50.72\n",
            "Test Set Loss: 54.69\n",
            "Train set accuracy for a single minibatch: 33.59%\n",
            "Test set accuracy for a single minibatch: 32.03%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 270\n",
            "Train Set Loss: 48.71\n",
            "Test Set Loss: 54.87\n",
            "Train set accuracy for a single minibatch: 39.84%\n",
            "Test set accuracy for a single minibatch: 33.59%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 300\n",
            "Train Set Loss: 48.68\n",
            "Test Set Loss: 53.82\n",
            "Train set accuracy for a single minibatch: 41.41%\n",
            "Test set accuracy for a single minibatch: 36.72%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 330\n",
            "Train Set Loss: 55.88\n",
            "Test Set Loss: 49.54\n",
            "Train set accuracy for a single minibatch: 38.28%\n",
            "Test set accuracy for a single minibatch: 31.25%\n",
            "\n",
            "\n",
            "Epoch 2, Iteration 360\n",
            "Train Set Loss: 57.62\n",
            "Test Set Loss: 47.48\n",
            "Train set accuracy for a single minibatch: 32.03%\n",
            "Test set accuracy for a single minibatch: 40.62%\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "# drop_last switched to False to keep all samples\n",
        "test_loader = DataLoader(CIFAR10_test, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "  net.eval()\n",
        "  for data, targets in test_loader:\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    test_spk, _ = net(data.view(data.size(0), -1))\n",
        "\n",
        "    # calculate total accuracy\n",
        "    _, predicted = test_spk.sum(dim=0).max(1)\n",
        "    total += targets.size(0)\n",
        "    correct += (predicted == targets).sum().item()"
      ],
      "metadata": {
        "id": "KmeuXeRUKy6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
        "print(f\"Test Set Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehyzVITbLMl9",
        "outputId": "40a4ce09-67f5-4516-802e-99271c3b074c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correctly classified test set images: 3400/10000\n",
            "Test Set Accuracy: 34.00%\n"
          ]
        }
      ]
    }
  ]
}